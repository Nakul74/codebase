{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Function to scrape a webpage using BeautifulSoup\n",
    "def scrapper_soup(url):\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# URL to scrape\n",
    "url = 'https://xyz.com'\n",
    "# Call the scrapper_soup function to get the BeautifulSoup object\n",
    "soup = scrapper_soup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the first div with class 'banner-title'\n",
    "banner_title_text = soup.find('div', {'class': 'banner-title'}).text.strip()\n",
    "\n",
    "# Extract text with line breaks from the first div with class 'banner-title'\n",
    "banner_title_text_with_line_breaks = soup.find('div', {'class': 'banner-title'}).get_text(separator='\\n')\n",
    "\n",
    "# Extract the 'href' attribute from the first anchor with 'uflix' in the 'href'\n",
    "uflix_href = soup.find('a', href=re.compile('uflix')).get('href')\n",
    "\n",
    "# Extract contents from the first div with a class matching the regular expression 'torrent-category*'\n",
    "torrent_category_contents = soup.find('div', {'class': re.compile('torrent-category*')}).contents\n",
    "torrent_category_contents = soup.find('div', {'class': re.compile('magnet')}).get('href')\n",
    "\n",
    "\n",
    "# Extract text from the first span element\n",
    "span_text = soup.find('span').getText()\n",
    "\n",
    "# Find the element with id 'link3'\n",
    "element_with_id_link3 = soup.find(id=\"link3\")\n",
    "\n",
    "# Extract the 'src' attribute from the first img element\n",
    "img_src = soup.find('img')['src']\n",
    "\n",
    "# Select all 'a' elements with an 'href' attribute starting with 'magnet'\n",
    "#css selector\n",
    "magnet_links = soup.select_one('a[href^=\"magnet\"]')\n",
    "magnet_links = soup.select('a[href^=\"magnet\"]')\n",
    "\n",
    "# Extract all 'a' elements that come after the current position\n",
    "all_next_a_elements = soup.find_all_next('a')\n",
    "\n",
    "# Extract all 'a' elements that come before the current position\n",
    "all_previous_a_elements = soup.find_all_previous('a')\n",
    "\n",
    "# Find the next sibling 'p' element\n",
    "next_sibling_p = soup.find_next_sibling('p')\n",
    "\n",
    "# Find the previous sibling 'p' element\n",
    "previous_sibling_p = soup.find_previous_sibling('p')\n",
    "\n",
    "# Find the parent 'div' element\n",
    "parent_div = soup.find_parent('div')\n",
    "\n",
    "# Find all parent 'div' elements\n",
    "all_parents_div = soup.find_parents('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: you can also use 'find_all' command instead of 'find' to get all elements that matches the pattern.\n",
    "\n",
    "* Note: similar to 'find_all' you can also use 'select' command instead of 'select_one' to get all elements that matches the pattern."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
