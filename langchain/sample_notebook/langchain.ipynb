{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = '/app/dir_path'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1024,chunk_overlap=30):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))\n",
    "\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = []\n",
    "for idx,row in df.iterrows():\n",
    "    doc =  Document(page_content=row['Question'], metadata={\"answer\": row['Answer']})\n",
    "    docs.append(doc)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.save_local(vect_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "path = '/home/ubuntu/projects/pipeline/data_storage/vect_db/2023_11_12_19_34_36'\n",
    "vectorstore = FAISS.load_local(path, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Hello I’m from Niagara and our school is Kate Durban what is your program about what meals are available and what’s the difference between you and lunch box?'\n",
    "r = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.0, openai_api_key=\"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\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"score_threshold\": .5})\n",
    "\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory,verbose=True)\n",
    "\n",
    "qa.run({'question':'tell me about goglocal?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "model_name = 'gpt-3.5-turbo-16k'\n",
    "chat_model = ChatOpenAI(temperature=0.0, model_name=model_name, openai_api_key=openai_api_key)\n",
    "\n",
    "response_schemas = []\n",
    "response_schemas.append(ResponseSchema(name=\"email_subject\", description=\"subject of email based on context\"))\n",
    "response_schemas.append(ResponseSchema(name=\"email_body\", description=\"body of email based on context\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_template = \"\"\"Warmest regards,\n",
    "Customer Service Team\n",
    "support@foodforgood.ca\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_query = (\n",
    "            \"You are a marketing specialist at FoodForGood. Your responsibility is to respond to the sender's \"\n",
    "            \"email using the company context provided below. Ensure that your reply is professional and \"\n",
    "            \"incorporates the specified end template for concluding the email response. The sender's email, \"\n",
    "            \"company context, and end template are provided, so be sure to utilize them to craft a professional \"\n",
    "            \"subject and body for the email.It is crucial to precisely respond to each inquiry in the email by \"\n",
    "            \"leveraging the company context provided below.\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '##'*30\n",
    "# input_prompt_query = \"Your task is to craft an email response, encompassing both the subject line and body, using the supplied email content. The email context comprises a combination of questions and email response templates. It is essential to maintain a professional tone in the response and refrain from presenting any inaccurate information beyond the provided context. Additionally, conclude the email with the provided end template.\"\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nSender\\'s Email:\\n{input_email}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nEnd Template:\\n{end_template}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nCompany Context:\\n{context}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += \"\\n\\n{format_instructions}\\n\"\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_email = \"\"\"Hi, I am parent from haximar school. can you tell me steps to signup for the program for my child?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Hi, I am parent from haximar school. can you tell me steps to signup for the program for my child?\"\"\"\n",
    "r = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ['Q.' + i.page_content.strip() + '\\nA.' + i.metadata['answer'].strip() for i in r]\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context = '\\n'.join(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = []\n",
    "input_variables.append(\"input_email\")\n",
    "input_variables.append(\"context\")\n",
    "input_variables.append(\"end_template\")\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(input_prompt_query)  \n",
    "    ],\n",
    "    input_variables=input_variables,\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "      \n",
    "input_prompt = prompt.format_prompt(input_email = full_email,\n",
    "                                   context = input_context,\n",
    "                                   end_template = end_template)\n",
    "    \n",
    "print(input_prompt.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_response = chat_model(input_prompt.to_messages())\n",
    "parse_response = output_parser.parse(gpt_response.content)\n",
    "parse_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "path = '/home/ubuntu/projects/pipeline/data_storage/vect_db/2023_11_12_19_34_36'\n",
    "vectorstore = FAISS.load_local(path, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
