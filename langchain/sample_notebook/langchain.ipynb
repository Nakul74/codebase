{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create langchain docs from folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = '/app/dir_path'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1024,chunk_overlap=30):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom langchain docs with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "d = {'how are you?':'I am fine',\n",
    "     'what is your name?':'My name is smith'}\n",
    "\n",
    "docs = []\n",
    "for question,answer in d.items():\n",
    "    doc =  Document(page_content=question, metadata={\"answer\": answer})\n",
    "    docs.append(doc)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create retriever using chromadb\n",
    "* For more information visit [chroma langchain](https://python.langchain.com/docs/integrations/vectorstores/chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": .5})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create retriever using FAISS\n",
    "* For more information visit [FAISS langchain](https://python.langchain.com/docs/integrations/vectorstores/FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": .5})\n",
    "# retriever = vectorstore.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save database\n",
    "vectorstore.save_local('faiss_index')\n",
    "\n",
    "#load database\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", openai_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faiss vectorstore to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_vectorstore_df(vectorstore):\n",
    "    d = vectorstore.docstore._dict\n",
    "    data_rows = []\n",
    "    for chunk_id,content in d.items():\n",
    "        s1 = {\"chunk_id\": chunk_id,\n",
    "            \"content\": content.page_content.strip()}\n",
    "        s = {**s1,**content.metadata}\n",
    "        data_rows.append(s)\n",
    "        \n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faiss vectorstore delete records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note chunk id you can get from dataframe\n",
    "chunk_id_list = ['abcd','xxxx']\n",
    "vectorstore.delete(ids=chunk_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faiss vectorstore add new record docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "d = {'how are you?':'I am fine',\n",
    "     'what is your name?':'My name is smith'}\n",
    "\n",
    "docs = []\n",
    "for question,answer in d.items():\n",
    "    doc =  Document(page_content=question, metadata={\"answer\": answer})\n",
    "    docs.append(doc)\n",
    "    \n",
    "vectorstore.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you have done update and delete you can \n",
    "# save your database\n",
    "vectorstore.save_local('faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding top k similar docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'how many awards did messi won?'\n",
    "similar_docs = retriever.get_relevant_documents(query)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using retrievers as chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "openai_embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.0, openai_api_key=openai_api_key)\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory,verbose=True)\n",
    "\n",
    "qa.run({'question':'tell me about goglocal?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom langchain response generation using retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "openai_api_key = 'xxx'\n",
    "model_name = 'gpt-3.5-turbo-16k'\n",
    "chat_model = ChatOpenAI(temperature=0.0, model_name=model_name, openai_api_key=openai_api_key)\n",
    "\n",
    "response_schemas = []\n",
    "response_schemas.append(ResponseSchema(name=\"email_subject\", description=\"subject of email based on context\"))\n",
    "response_schemas.append(ResponseSchema(name=\"email_body\", description=\"body of email based on context\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_query = (\n",
    "            \"You are a marketing specialist at FoodForGood. Your responsibility is to respond to the sender's \"\n",
    "            \"email using the company context provided below. Ensure that your reply is professional and \"\n",
    "            \"incorporates the specified end template for concluding the email response. The sender's email, \"\n",
    "            \"company context, and end template are provided, so be sure to utilize them to craft a professional \"\n",
    "            \"subject and body for the email.It is crucial to precisely respond to each inquiry in the email by \"\n",
    "            \"leveraging the company context provided below.\\n\"\n",
    "        )\n",
    "\n",
    "s = '##'*30\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nSender\\'s Email:\\n{input_email}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nEnd Template:\\n{end_template}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += '\\n\\nCompany Context:\\n{context}\\n\\n'\n",
    "input_prompt_query += s\n",
    "input_prompt_query += \"\\n\\n{format_instructions}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_email = \"\"\"Hi, I am parent from haximar school. can you tell me steps to signup for the program for my child?\"\"\"\n",
    "similar_docs = retriever.get_relevant_documents(full_email)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar docs if metadata is given\n",
    "similar_docs = ['Q.' + i.page_content.strip() + '\\nA.' + i.metadata['answer'].strip() for i in similar_docs]\n",
    "len(similar_docs)\n",
    "\n",
    "# similar docs without metadata\n",
    "similar_docs = [i.page_content.strip() for i in similar_docs]\n",
    "len(similar_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_template = \"\"\"Warmest regards,\n",
    "Customer Service Team\n",
    "support@foodforgood.ca\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context = '\\n'.join(similar_docs)\n",
    "print(input_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = []\n",
    "input_variables.append(\"input_email\")\n",
    "input_variables.append(\"context\")\n",
    "input_variables.append(\"end_template\")\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(input_prompt_query)  \n",
    "    ],\n",
    "    input_variables=input_variables,\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "      \n",
    "input_prompt = prompt.format_prompt(input_email = full_email,\n",
    "                                   context = input_context,\n",
    "                                   end_template = end_template)\n",
    "    \n",
    "print(input_prompt.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_response = chat_model(input_prompt.to_messages())\n",
    "parse_response = output_parser.parse(gpt_response.content)\n",
    "parse_response"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
